{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertConfig,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from model.bert_configs import shadow, target\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\", split=[\"train+test\"])[0].train_test_split(\n",
    "    test_size=0.5, stratify_by_column=\"label\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    lambda x: tokenizer(\n",
    "        x[\"text\"], return_tensors=\"pt\", padding=True, max_length=512, truncation=True\n",
    "    ),\n",
    "    batched=True,\n",
    ")\n",
    "tokenized_dataset.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_subset = tokenized_dataset[\"train\"].train_test_split(\n",
    "    test_size=0.5, stratify_by_column=\"label\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SHADOWS = 10\n",
    "\n",
    "shadow_subsets = []\n",
    "for i in range(N_SHADOWS):\n",
    "    shadow_subsets.append(\n",
    "        tokenized_dataset[\"test\"].train_test_split(\n",
    "            test_size=0.5, stratify_by_column=\"label\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bert_config = BertConfig(**target)\n",
    "target_classifier = BertForSequenceClassification(config=target_bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"saved_models/target\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=target_classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=target_subset[\"train\"],\n",
    "    eval_dataset=target_subset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d8f3dfad5f453395e2619fb7e063b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3388, 'grad_norm': 8.534919738769531, 'learning_rate': 4.9085923217550275e-05, 'epoch': 0.18}\n",
      "{'loss': 1.0463, 'grad_norm': 18.86072540283203, 'learning_rate': 4.817184643510055e-05, 'epoch': 0.37}\n",
      "{'loss': 1.0083, 'grad_norm': 6.08780574798584, 'learning_rate': 4.725776965265082e-05, 'epoch': 0.55}\n",
      "{'loss': 0.9996, 'grad_norm': 5.470260143280029, 'learning_rate': 4.63436928702011e-05, 'epoch': 0.73}\n",
      "{'loss': 0.973, 'grad_norm': 11.012569427490234, 'learning_rate': 4.542961608775137e-05, 'epoch': 0.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32ffd2d0c5a4be4932676b4b16f4b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2735 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Shadows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_bert_config = BertConfig(**shadow)\n",
    "for i in range(N_SHADOWS):\n",
    "    shadow_classifier = BertForSequenceClassification(config=shadow_bert_config)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"saved_models/shadow_{i}\",\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=64,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=shadow_classifier,\n",
    "        args=training_args,\n",
    "        train_dataset=shadow_subsets[i][\"train\"],\n",
    "        eval_dataset=shadow_subsets[i][\"test\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Attacker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "attack_dataset_X = []  # shadow model predicition scores\n",
    "attack_dataset_y = []  # membership / non-membership\n",
    "\n",
    "for i in range(10):\n",
    "    shadow_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        f\"saved_models/shadow_{i}\"\n",
    "    )\n",
    "    shadow_train_dl = DataLoader(shadow_subsets[i][\"train\"], batch_size=100)\n",
    "    shadow_test_dl = DataLoader(shadow_subsets[i][\"test\"], batch_size=100)\n",
    "    shadow_model.eval()\n",
    "    for batch in shadow_train_dl:\n",
    "        with torch.inference_mode():\n",
    "            logits = shadow_model(**batch)[\"logits\"]\n",
    "        probs = F.softmax(logits, dim=-1).cpu().numpy()\n",
    "        attack_dataset_X.append(probs)\n",
    "        attack_dataset_y.append(np.ones(len(probs)))\n",
    "    for batch in shadow_test_dl:\n",
    "        with torch.inference_mode():\n",
    "            logits = shadow_model(**batch)[\"logits\"]\n",
    "        probs = F.softmax(logits, dim=-1).cpu().numpy()\n",
    "        attack_dataset_X.append(probs)\n",
    "        attack_dataset_y.append(np.zeros(len(probs)))\n",
    "\n",
    "attack_X_train = np.hstack(attack_dataset_X)\n",
    "attack_y_train = np.hstack(attack_dataset_y)\n",
    "\n",
    "np.savez_compressed(\n",
    "    \"saved_datasets/attack_train_dataset\",\n",
    "    attack_X_train=attack_X_train,\n",
    "    attack_y_train=attack_y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base_xgb_attacker = XGBClassifier(objective=\"binary:logistic\", eval_metric=\"auc\")\n",
    "gridsearch_clf = GridSearchCV(\n",
    "    base_xgb_attacker,\n",
    "    {\n",
    "        \"max_depth\": [1, 2, 3, 4, 5],\n",
    "        \"n_estimators\": [2, 5, 10, 50]\n",
    "    },\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gridsearch_clf.fit(attack_X_train, attack_y_train)\n",
    "best_xgb_attacker = gridsearch_clf.best_estimator_\n",
    "best_xgb_attacker.save_model(\"saved_models/attacker/XGB_attacker.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(attack_y_train, best_xgb_attacker.predict_proba(attack_X_train)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "attack_dataset_X = []  # target model predicition scores\n",
    "attack_dataset_y = []  # membership / non-membership\n",
    "\n",
    "target_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"saved_models/target\"\n",
    ")\n",
    "target_train_dl = DataLoader(target_subset[\"train\"], batch_size=100)\n",
    "target_test_dl = DataLoader(target_subset[\"test\"], batch_size=100)\n",
    "target_model.eval()\n",
    "for batch in target_train_dl:\n",
    "    with torch.inference_mode():\n",
    "        logits = target_model(**batch)[\"logits\"]\n",
    "    probs = F.softmax(logits, dim=-1).cpu().numpy()\n",
    "    attack_dataset_X.append(probs)\n",
    "    attack_dataset_y.append(np.ones(len(probs)))\n",
    "for batch in target_test_dl:\n",
    "    with torch.inference_mode():\n",
    "        logits = target_model(**batch)[\"logits\"]\n",
    "    probs = F.softmax(logits, dim=-1).cpu().numpy()\n",
    "    attack_dataset_X.append(probs)\n",
    "    attack_dataset_y.append(np.zeros(len(probs)))\n",
    "\n",
    "attack_X_test = np.hstack(attack_dataset_X)\n",
    "attack_y_test = np.hstack(attack_dataset_y)\n",
    "\n",
    "np.savez_compressed(\n",
    "    \"saved_datasets/attack_test_dataset\",\n",
    "    attack_X_test=attack_X_test,\n",
    "    attack_y_test=attack_y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
